---
title: "Predicting the probability of a red car getting a traffic violation."
author: "Angel Soriano, Miriam Flores, Noemi Cuin "
date: "May 12, 2017"
output:
  html_document: default
  pdf_document: default
---

It has been rumored that red cars tend to get more traffic violations more often than any other color of car. Our calculations will be used to see if this rumor is a myth or if the data gathered from a 2017 data set of traffic violations across the country will reflect differently.

Prior to analyzing the data, we first need to clean it of any empty values and then split the data into test and training sets.

### Libraries
```{r}
library(e1071)
library(rpart)
library(rpart.plot)
source("../lin-regr-util.R")
```
 
### Data input and cleaning 
```{r}
dat = read.csv('../Traffic_Violations.csv')

# remove rows tha contain data that will make our analysis more 


dat = dat[dat$Color!="N/A",]
dat = dat[dat$Gender != "U",]
dat = dat[dat$State != "XX",]
dat = dat[dat$Make != "UNKNOWN",]

# switch col names to lowercase
colnames(dat) = tolower(colnames(dat))

# remove any data with NA values
dat = na.omit(dat)

# adding an output column that checks whether car color is red or not 
dat$output = NA
dat$output = ifelse(dat$color == "RED",1,0)
dat$output = as.factor(dat$output)

#if traffic violation is speeding == yes else == no
#dat$speeding = NA
#dat$speeding = ifelse(grepl("SPEED|EXCEED|MPH|MAXIMUM", dat$description),'yes','no')
#dat$speeding = as.factor(dat$speeding)
```

###Data Exploration and Visualization
To get an idea of what we're working with, we should build some histograms and tables to vizualize the types of violations our data has as well as the diffe#Remove unkowns from gender rent colors and models of cars.Because there's so much data, we're going to take the top 10 models and colors of the cars, as well as the top 10 traffic violations and build from there. 

```{r}
#par(mfrow=c(3,1))
violationNames=head(sort(table(dat$description),decreasing=TRUE),10)
names(violationNames)=tolower(c("NOT FOLLOWING TRAFFIC INSTRUCTIONS","NO REGISTRATION","DRIVING WITH SUSPENDED REGISTRATION","DRIVING W/O A LICENSE","USING PHONE WHILE DRIVING","EXPIRED REGISTRATION","FAILURE TO STOP AT STOP SIGN","DRIVING W/SUSPENDED LICENSE","DRIVING W/O SEATBELT","DRIVING OVER SPEED LIMIT"))


par(mar=c(5,14,4,0.1))
barplot(head(sort(table(dat$color),decreasing=TRUE),10),horiz=TRUE,las=1)
barplot(head(sort(table(dat$make),decreasing=TRUE),10),horiz=TRUE,las=1)
barplot(violationNames,horiz=TRUE,las=1)
#barplot(head(sort(table(dat$Description),decreasing=TRUE),10),horiz=TRUE,las=1)

```
Analyzing our processed data, we can see that red cars rank in 5th in the top 10 colors of cars with traffic violations.
###TRIOGRAM 
```{r}
descriptions = tolower(tr_dat$description)
words = strsplit(descriptions, " ")
for(description in descriptions){
  sentence = strsplit(description, " ")
  
}

#rmv = c("to", "on", "of", "in")
ws = c()

for(word in words){
  for(x in 2:(length(word)-1)){
    ws = append(ws, paste(word[x-1], paste(word[x], word[x+1])))  
  }
}
#most_words <- most_words[!most_words %in% rmv]

most_words = sort(table(ws), decreasing = TRUE)


head(most_words, n=10)
```

###Data Preprocessing
```{r}
#split our data into test and training data 
set.seed(123)
traffic_data = split_data(dat, c(0.005, .005, .995))
te_dat = traffic_data[[1]]
t3_dat = traffic_data[[2]]
tr_dat = traffic_data[[3]]
t3_dat$speeding = ifelse(grepl("SPEED|EXCEED|MPH|MAXIMUM", t3_dat$description),'yes','no')
t3_dat$speeding = as.factor(t3_dat$speeding)
te_dat$speeding = ifelse(grepl("SPEED|EXCEED|MPH|MAXIMUM", te_dat$description),'yes','no')
te_dat$speeding = as.factor(te_dat$speeding)
```

### How likely is the car that got pulled over red ?
```{r}

model1 = naiveBayes(speeding ~ make + model, data = t3_dat)

predictions = predict(model1, newdata = te_dat)
actuals = te_dat$speeding

conf.matrix = table(actuals, predictions)
conf.matrix

mean(actuals == predictions)

```

The probability of a car being ulled over & having it be red in Maryland is very low because the mean of our predicted probability is about 10%.
We can to this conclusion after taking predictions based 

### DECISON TREE : 
```{r}
model2 = rpart(speeding ~ make+model+geolocation+location, data=t3_dat,method = "class")
#model2 = rpart(speeding ~., data=t3_dat,method = "class")

predictions = predict(model2, newdata = te_dat, type="class")
actuals = te_dat$speeding

conf.matrix = table(actuals, predictions)
conf.matrix
mean(actuals == predictions)

```
### MODEL 2 Analysis 
```{r}
plotcp(model2)
printcp(model2)
```

### add color as a factor in our model 
```{r}


```



